# CSC-305 — Compiler Design
---

## Requirements & Dependencies

To build and run the code in this repository you will need the following tools installed on your development machine (instructions assume a Linux environment):

* `flex` — fast lexical analyzer generator
* `g++` — GNU C++ compiler
* `libfl-dev` (or equivalent) — development library for linking `flex` generated code
* `make` — build automation utility

Example installation on Debian/Ubuntu/WSL:

```bash
sudo apt update
sudo apt install build-essential flex libfl-dev make
```

---

## Repo layout

```
.
├── makefile          # build rules
├── run.sh            # convenience script to run lexer on all tests
├── README.md
├── src/
│   ├── lex.l         # flex lexer source
│   ├── lex.yy.c      # generated by flex (target of make)
│   └── lexer         # generated executable (target of make)
├── test/
│   ├── test1.txt
│   ├── test2.txt
│   └── ...           # input test files
└── output/
    ├── output1.txt   # generated output tables
    └── error_output1.txt
```

---

## Features

* A working lexer (implemented in `src/lex.l`) that recognizes C/C++-style tokens: keywords, identifiers, literals, operators, and punctuation.
* Output of a human-readable ASCII token table with columns: `Line No | Lexeme | Token`.
* Error reporting to a separate `error_<output_file>` showing `INVALID_IDENTIFIER` and `INVALID_TOKEN` entries.
* Simple `Makefile` to generate `lex.yy.c` and build the executable `src/lexer`.
* `run.sh` to run the lexer on several test input files and write results to `output/`.

---

### Phase 1 — Lexer 

**Location:** `src/lex.l`

**What it does:**

* Tokenizes input source files into tokens such as `INT`, `FLOAT`, `IDENTIFIER`, `INCLUDE`, operators (`+`, `-`, `*`, `/`, `==`, `<=`, ...), punctuation (`;`, `,`, `{`, `}`), and string/number literals.
* Writes a formatted ASCII table of recognized tokens to the user-specified output file.
* Writes lexical errors (invalid tokens or malformed identifiers) to `error_<output_file>`.

---

## Running the project

### Build

From the project root:

```bash
# generate src/lex.yy.c and build the executable
make
```

Makefile targets:

* `lexer` — runs `flex` to generate `src/lex.yy.c` and compiles it with `g++ -lfl` to `src/lexer`.
* `clean` — removes generated files (`src/lex.yy.c` and `src/lexer`).

```bash
make clean
# removes src/lex.yy.c and src/lexer
```

### Run a single test

```bash
# usage: ./src/lexer <input_file> <output_file>
./src/lexer test/test1.txt output/output1.txt
```

This will also write lexical errors to `error_output/output1.txt` (for example `error_output1.txt`).

### Batch runs

A convenience script `run.sh` runs the lexer on multiple `test/` files and writes output to `output/`:

```bash
chmod +x run.sh
./run.sh
# run.sh runs the lexer on multiple test files and writes them to `output/`
```

### Output format

Two files per run:

1. `<output_file>` — formatted ASCII table of recognized tokens.
```
+---------+---------------------+--------------------------+
| Line No | Lexeme              | Token                    |
+---------+---------------------+--------------------------+
| 1       | #include <stdio.h>  | INCLUDE                  |
+---------+---------------------+--------------------------+
| 2       | int                 | INT                      |
+---------+---------------------+--------------------------+
...
```
2. `error_<output_file>` — formatted table of lexical errors (`INVALID_IDENTIFIER`, `INVALID_TOKEN`).

### Return codes

* `0` on success
* `1` on usage or file-open errors

---

### Contributors 
* Kartik Sarda - 23114047
* Nitin Agiwal - 23114074
* Adesh Kaduba Palkar - 23114004
* Utkarsh Kumar - 23114101
